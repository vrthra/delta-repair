%%
%% This is file `sample-acmsmall-conf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,proceedings,bibtex,acmsmall-conf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-acmsmall-conf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\PassOptionsToPackage{noend}{algorithmic} % before \documentclass
\documentclass[acmsmall,screen,review,anonymous]{acmart}

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmlicensed}
\copyrightyear{2018}
\acmYear{2018}
\acmDOI{XXXXXXX.XXXXXXX}

%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[Conference acronym 'XX]{Make sure to enter the correct
  conference title from your rights confirmation emai}{June 03--05,
  2018}{Woodstock, NY}
%%
%%  Uncomment \acmBooktitle if the title of the proceedings is different
%%  from ``Proceedings of ...''!
%%
%%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%%  June 03--05, 2018, Woodstock, NY}
\acmISBN{978-1-4503-XXXX-X/18/06}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}


%%
%% end of the preamble, start of the body of the document source.

\usepackage{subcaption}
\usepackage{amsmath,amsfonts}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{wrapfig}

\usepackage{algorithm}
%\usepackage{algorithmic}
\usepackage[noend]{algpseudocode}


\usepackage{listings}

\lstset{ % General setup for the package
    language=Python,
    %basicstyle=\small\sffamily,
    %basicstyle=\footnotesize,  % *Please* use a monospaced font -- AZ
    basicstyle=\footnotesize\ttfamily,
    numbers=left,
    numberstyle=\tiny,
    frame=none,
    tabsize=4,
    columns=flexible,
    keepspaces=true,
    showstringspaces=false,
    showtabs=false,
    keepspaces,
    commentstyle=\color{green},
    keywordstyle=\color{blue},
    xleftmargin=1.45in
}
\usepackage{xspace}
\usepackage{array,multirow,graphicx}
\usepackage{float}
\usepackage{framed}
\usepackage{tikz,pgfplots,pgfplotstable}
\usetikzlibrary{calc,positioning,patterns}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{boxedminipage}
\usepackage[inline]{enumitem}
\usepackage[normalem]{ulem}

\newenvironment{result}{\begin{framed}\centering\it}{\end{framed}}

\newcounter{todocounter}
\newcommand{\todo}[1]{\marginpar{$|$}\textcolor{red}{\stepcounter{todocounter}\footnote[\thetodocounter]{\textcolor{red}{\textbf{TODO }}\textit{#1}}}}
\newcommand{\done}[1]{\marginpar{$*$}\textcolor{green}{\stepcounter{todocounter}\footnote[\thetodocounter]{\textcolor{black}{\textbf{DONE }}\textit{#1}}}}

\newcommand{\recheck}[1]{\textcolor{red}{#1}}
\newcommand{\revise}[1]{\textcolor{black}{#1}}

\renewcommand{\done}[1]{} % comment to see responses.


\IfFileExists{SUBMIT}{
\renewcommand{\todo}[1]{}
\renewcommand{\done}[1]{}
}{
}

\newcommand{\Formatfree}{Format-free\xspace}
\newcommand{\formatfree}{format-free\xspace}
\newcommand{\formatdependent}{format-dependent\xspace}
\newcommand{\Formatdependent}{Format-dependent\xspace}

\newcommand{\dtask}{data repair\xspace}
\newcommand{\Dtask}{Data repair\xspace}
\newcommand{\dd}{\textit{dd}\xspace}
\newcommand{\ddmin}{\textit{ddmin}\xspace}
\newcommand{\test}{\textit{test}\xspace}

\definecolor{nontermcolor}{rgb}{0.4, 0.05, 0.0} % dark orange
\definecolor{absnontermcolor}{rgb}{0.4, 0.5, 0.0} % light green
\definecolor{evokcolor}{rgb}{0.8, 0.05, 0.1}    % orange
\definecolor{incorrectcolor}{rgb}{0.5, 0.0, 0.13}
\definecolor{incompletecolor}{rgb}{0.0, 0.0, 0.55}
%\definecolor{incompletecolor}{rgb}{0.12, 0.3, 0.17}
\definecolor{validcolor}{rgb}{0.33, 0.42, 0.18} %  {0.0, 0.28, 0.67}
%\definecolor{retcolor}{rgb}{0.43, 0.21, 0.1}
\definecolor{retcolor}{rgb}{0.65, 0.16, 0.16}
\definecolor{ipatterncolor}{rgb}{0.0, 0.5, 0.4} % cyan?
\definecolor{termcolor}{rgb}{0.0, 0.05, 0.4}    % dark blue
\definecolor{regexcolor}{rgb}{0.1, 0.3, 0.1}    % dark green


\def\Rincomplete{\texttt{\color{incompletecolor}\textbf{$\vartriangleright$}}\xspace}
%\def\Rincorrect{\texttt{\color{incorrectcolor}\textbf{$\ntriangleright$}}\xspace}
\def\Rincorrect{\texttt{\color{incorrectcolor}\textbf{$\ntriangleright$}}\xspace}
\def\Rvalid{\texttt{\color{validcolor}\textbf{$\checkmark$}}\xspace}
\def\Rreject{\texttt{\color{incorrectcolor}\textbf{$\times$}}\xspace}

%\newcommand{\cmark}{\ding{51}}%


%\renewcommand{\tablename}{Tab.}
%\renewcommand{\figurename}{Fig.}
%\renewcommand{\algorithmname}{Alg.}
%\renewcommand{\listalgorithmname}{Alg.}


\usepackage{pifont}
%\newcommand{\pass}{\text{\ding{52}}\xspace}
%\newcommand{\fail}{\text{\ding{56}}\xspace}
\newcommand{\pass}{\text{\Rvalid}\xspace}
\newcommand{\fail}{\text{\Rreject}\xspace}


\newcommand{\unresolved}{\lower0.1ex\hbox{\includegraphics*[height=1.7ex]{question.pdf}}}


\newcommand{\cpass}{{c_{\scriptscriptstyle \pass}}}
\newcommand{\cfail}{{c_{\scriptscriptstyle \fail}}}
\newcommand{\dpass}{{c'_{\scriptscriptstyle \pass}}}
\newcommand{\dfail}{{c'_{\scriptscriptstyle \fail}}}


\newcommand{\approach}{\textsc{$\Delta$Repair}\xspace}
\def\bfr{bFuzzerRepairer\xspace}
\def\ddmin{DDMin\xspace}
\newcommand{\ddmax}{\textit{DDMax}\xspace}
\newcommand{\ddmaxg}{\textit{DDmaxG}\xspace}
\newcommand{\bsimple}{\textit{bsimple}\xspace}
\newcommand{\drepair}{\approach}

\tikzset{inlinenode/.style={draw=white,text=black,fill=light-gray,inner sep=.1em,outer sep=0em}}
\newcommand{\inlinenode}[1]{\text{\hspace{.1em}\tikz[baseline=(n.base)]{\node[inlinenode] (n) {\strut \hspace*{.3em}#1\hspace*{.3em}};}\hspace{.1em}}}
\newcommand{\inlinetext}[1]{\text{\hspace{.1em}\tikz[baseline=(n.base)]{\node[inlinenode] (n) {\strut \hspace*{.3em}\letterboxed{#1}\hspace*{.3em}};}\hspace{.1em}}}
\newcommand*\circled[1]{\tikz[baseline=(char.base)]{
            \node[shape=circle,draw,inner sep=0.3pt] (char) {#1};}}

\tikzset{%
simpletext/.style={draw=none,text=black,font=\normalfont\normalsize,align=center},
gparsetreenode/.style={minimum width=6mm,minimum height=5mm},
lparsetreenode/.style={gparsetreenode,simpletext,rectangle,draw=white,fill=white,align=center},
lparsetreeerrornode/.style={lparsetreenode,font=\bfseries},
lparsetreephantomnode/.style={gparsetreenode,edge from parent/.append style={draw=none},shape=coordinate,minimum width=15mm},
lparsetreestrikethrough/.style={draw=black,thick},
lparsetreedeletednode/.style={lparsetreenode,append after command={\pgfextra \draw[lparsetreestrikethrough] (\tikzlastnode.north west) -- (\tikzlastnode.south east); \draw[lparsetreestrikethrough] (\tikzlastnode.north east) -- (\tikzlastnode.south west);\endpgfextra}},
lparsetree/.style={node distance=5mm,level distance=10mm,every node/.style={lparsetreenode},edge from parent/.style={draw=black,-latex,shorten >=.5mm}
},
lflowchartnode/.style={lparsetreenode,draw=black,rounded corners=.5pt},
blockdiagramlines/.style={draw,stroke=black,line width=1.2pt},
blockdiagramarrow/.style={blockdiagramlines,->},
blockdiagramdashedarrow/.style={blockdiagramarrow,dashed},
blockdiagramannot/.style={blockdiagramlines,text=black,align=center},
blockdiagramblock/.style={lflowchartnode,blockdiagramannot,minimum width=2.5cm,minimum height=0.65cm,text width=2.9cm},
blockdiagrammicroblock/.style={blockdiagramannot,font=\tiny,minimum width=1.5cm,minimum height=.5cm,rounded corners=.5pt},
blockdiagramarrowcaption/.style={font=\scriptsize\sffamily,inner sep=1.5pt,text=black},
blockdiagramouterbox/.style={blockdiagramlines,densely dotted,line width=.7pt},
blockdiagramouterboxcaption/.style={blockdiagramarrowcaption,font=\itshape\scriptsize,inner sep=1pt},
pics/numbering/.style args={#1}{code={
    \node[draw=black,shape=circle,fill=white,text=black,font=\ttfamily\scriptsize,inner sep=1pt,text width=8pt,align=center,outer sep=0] (-number) {#1};
}}}

\definecolor{light-gray}{gray}{0.77}
\makeatletter

\newcommand\letterboxed[1]{%
\setlength{\fboxsep}{0pt}%
  \@tfor\@ii:=#1\do{%
    \fcolorbox{light-gray}{white}%
    %\uline
    %\uline
    {\texttt{\strut\@ii}}%
  }%
}
\newcommand\letterboxedC[2]{%
\setlength{\fboxsep}{0pt}%
  \@tfor\@ii:=#2\do{%
    \fcolorbox{white}{#1}{\texttt{\strut\@ii}}%
  }%
}


\newcommand\letterboxedinTable[1]{%
\setlength{\fboxsep}{0pt}%
  \@tfor\@ii:=#1\do{%
    \fcolorbox{light-gray}{white}{\tiny \texttt{\strut\@ii}}%
  }%
}

\makeatother

\def\|#1|{\textit{#1}}
\def\<#1>{\texttt{#1}}


\usepackage{filecontents}




%--

\begin{filecontents*}{ddmaxlimitations.tex}
\begin{table*}\centering

\caption{\ddmax vs. \drepair: examples showing limitations of \ddmax and the strengths of \drepair}
{%\scriptsize
\begin{tabular}{|l | l | l | l |}
%\begin{tabular}{|l|p{2cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|}
\hline
\textbf{Examples of Corrupt}& \textbf{\ddmax} & \textbf{\drepair} & \textbf{\ddmax} \\
\textbf{Inputs} & \textbf{Result} & \textbf{Result} & \textbf{Limitation} \\
\hline
\letterboxedinTable{\{\ "name":\ "Dave"\ "age":\ 42\ \}} &
\letterboxedinTable{\ \ \ \ 42\ }  &
\letterboxedinTable{\{\ "name":\ "Dave"\ ,"age":\ 42\ \}} &
Limited repair \\
& & & options (deletion) \\
\hline
\letterboxedinTable{\{\ "item":\ "Apple",\ "price"} & \letterboxedinTable{\ \ \ \
3.45\ } & \letterboxedinTable{\{\ "item":\ "Apple",\ "price"} & Rich structure
\\
\letterboxedinTable{:\ ***3.45\}} & &\letterboxedinTable{:\ 3.45\}} &  (spans) \\
\hline
\letterboxedinTable{\{"ABCD":[*"1,2,3,4,5,6"]*\}} &
\letterboxedinTable{123456} &
\letterboxedinTable{\{"ABCD":["1,2,3,4,5,6"]\}} &
Rich structure\\

& & &  (multiple-faults)  \\
\hline
\letterboxedinTable{2024/07/23T12:34:56Z} &
\texttt{None}  &
\letterboxedinTable{2024-07-23T12:34:56Z} &
Require valid \\
& & & empty data\\
\hline
\end{tabular}}
\label{tab:ddmaxlimitations}
\end{table*}

\end{filecontents*}

\begin{document}
\title{Automatic Data Repair without Format Specifications}
%\title{Flexible and Automatic Data Repair Without Format Specifications}
\author{Lukas Kirschner}
\email{kirschlu@gmail.com}
\affiliation{%
  \institution{Saarland University}
  \country{Germany}
}

\author{Ezekiel Soremekun}
\affiliation{%
  \institution{Royal Holloway, University of London} % (RHUL)}
  \country{United Kingdom}} %nited Kingdom (UK)}}
\email{ezekiel.soremekun@rhul.ac.uk}

\author{Rahul Gopinath}
\email{rahul.gopinath@sydney.edu.au}
\affiliation{%
  \institution{University of Sydney}
  \country{Australia}
}


\renewcommand{\shortauthors}{Kirschner et al.}


% %%
% %% The "title" command has an optional parameter,
% %% allowing the author to define a "short title" to be used in page headers.
% 
% %%
% %% The "author" command and its associated commands are used to define
% %% the authors and their affiliations.
% %% Of note is the shared affiliation of the first two authors, and the
% %% "authornote" and "authornotemark" commands
% %% used to denote shared contribution to the research.
% \author{Ben Trovato}
% \authornote{Both authors contributed equally to this research.}
% \email{trovato@corporation.com}
% \orcid{1234-5678-9012}
% \author{G.K.M. Tobin}
% \authornotemark[1]
% \email{webmaster@marysville-ohio.com}
% \affiliation{%
%   \institution{Institute for Clarity in Documentation}
%   \city{Dublin}
%   \state{Ohio}
%   \country{USA}
% }
% 
% \author{Lars Th{\o}rv{\"a}ld}
% \affiliation{%
%   \institution{The Th{\o}rv{\"a}ld Group}
%   \city{Hekla}
%   \country{Iceland}}
% \email{larst@affiliation.org}
% 
% \author{Valerie B\'eranger}
% \affiliation{%
%   \institution{Inria Paris-Rocquencourt}
%   \city{Rocquencourt}
%   \country{France}
% }
% 
% \author{Aparna Patel}
% \affiliation{%
%  \institution{Rajiv Gandhi University}
%  \city{Doimukh}
%  \state{Arunachal Pradesh}
%  \country{India}}
% 
% \author{Huifen Chan}
% \affiliation{%
%   \institution{Tsinghua University}
%   \city{Haidian Qu}
%   \state{Beijing Shi}
%   \country{China}}
% 
% \author{Charles Palmer}
% \affiliation{%
%   \institution{Palmer Research Laboratories}
%   \city{San Antonio}
%   \state{Texas}
%   \country{USA}}
% \email{cpalmer@prl.com}
% 
% \author{John Smith}
% \affiliation{%
%   \institution{The Th{\o}rv{\"a}ld Group}
%   \city{Hekla}
%   \country{Iceland}}
% \email{jsmith@affiliation.org}
% 
% \author{Julius P. Kumquat}
% \affiliation{%
%   \institution{The Kumquat Consortium}
%   \city{New York}
%   \country{USA}}
% \email{jpkumquat@consortium.net}
% 
% %%
% %% By default, the full list of authors will be used in the page
% %% headers. Often, this list is too long, and will overlap
% %% other information printed in the page headers. This command allows
% %% the author to define a more concise list
% %% of authors' names for this purpose.
% \renewcommand{\shortauthors}{Trovato et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.

%This process is time-consuming and error-prone, especially when format specifications are incomplete or defined solely by their parsers.
\begin{abstract}
In data processing, engineers often work with datasets expected to conform to 
specific formats, but variations due to factors like human error or data 
corruption can cause inconsistencies. These inconsistencies prevent standard 
programs from processing the data correctly. As a result, data engineers must 
perform \emph{\dtask}, manually adjusting nonconforming data to match the 
required format. This process is time-consuming and error-prone, particularly 
when formal format specifications are unavailable, as data formats are often 
implicitly defined by their parsers.

In this paper, we introduce \drepair, a novel approach for automatic data 
repair that does not require predefined format specifications. \drepair adopts 
a \formatfree strategy, relying solely on parser feedback, making it a 
versatile solution capable of repairing even ad-hoc or informally specified 
data formats. We evaluate \drepair's performance against state-of-the-art 
techniques, including lexical and syntactic \ddmax, and ANTLR, using both 
synthetic and real-world datasets.

Our results show that \drepair achieves
31\% more perfect repairs, % VERIFIEDA
delivers 2$\times$ higher-quality repairs, % VERIFIEDB
and recovers 5.4$\times$ more % VERIFIEDC
intact data on average against the next best solution.
Although slightly slower, with an average runtime of 10 seconds, \drepair
provides a practical and highly effective solution, significantly
improving data recovery and repair quality.

This work expands the possibilities for automated data repair, offering a
flexible alternative to \formatdependent approaches.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
% \begin{CCSXML}
% <ccs2012>
%  <concept>
%   <concept_id>00000000.0000000.0000000</concept_id>
%   <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%   <concept_significance>500</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>00000000.00000000.00000000</concept_id>
%   <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%   <concept_significance>300</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>00000000.00000000.00000000</concept_id>
%   <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%   <concept_significance>100</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>00000000.00000000.00000000</concept_id>
%   <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%   <concept_significance>100</concept_significance>
%  </concept>
% </ccs2012>
% \end{CCSXML}
% 
% \ccsdesc[500]{Do Not Use This Code~Generate the Correct Terms for Your Paper}
% \ccsdesc[300]{Do Not Use This Code~Generate the Correct Terms for Your Paper}
% \ccsdesc{Do Not Use This Code~Generate the Correct Terms for Your Paper}
% \ccsdesc[100]{Do Not Use This Code~Generate the Correct Terms for Your Paper}
% 
% %%
% %% Keywords. The author(s) should pick words that accurately describe
% %% the work being presented. Separate the keywords with commas.
% \keywords{Do, Not, Us, This, Code, Put, the, Correct, Terms, for,
%   Your, Paper}
% %% A "teaser" image appears between the author and affiliation
% %% information and the body of the document, and typically spans the
% %% page.
% 
% \received{20 February 2007}
% \received[revised]{12 March 2009}
% \received[accepted]{5 June 2009}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
\label{sec:intro}

Large data repositories often contain corrupted data records with unintended errors.
These corruptions may be introduced when data is created (by humans or buggy programs), modified
(by external actors), or transmitted (via flawed networks)~\cite{scaffidi2008accommodating}.
For instance, many records are added by hand without validation, leading to
\textit{nonconforming records}~\cite{mucslu2015preventing}. Such nonconforming
records may also result from disagreements among data sources on format
specifications, leading to different implementations. For example, JSON
libraries implement slightly different definitions of JSON formats~\cite{harrand2021behavioral,seriot2016parsing},
different database systems support slightly different SQL formats~\cite{arvin2018comparison},
making their data dumps incompatible,
CSVs and similar data formats often differ between applications of the same
company~\cite{taocp}, and formats such as date and time from different sources
may often use different delimiters.

Even for rigid formats like XML, there's no guarantee
that a data record can be processed by a given parser, as the parser may
implement only a subset of the format~\cite{xmlconformance}.
These problems lead to records that cannot be processed by their intended
programs or used by data engineers.

Given such nonconforming records that are \emph{almost} but \emph{not quite}
parsable, developers are saddled with the task of \textit{\dtask}.
\Dtask is particularly important due to the high prevalence of nonconforming
records in data science and engineering~\cite{ridzuan2019review,kirschner2020debugging}.
It can be challenging to recover the conforming portion of nonconforming
data records automatically~\cite{scaffidi2008topes,ridzuan2019review},
and developers often have to either purge such records~\cite{hernandez1998real},
or \emph{manually} repair nonconforming parts of such records~\cite{kirschner2020debugging},
which is time-consuming and error-prone.

To address these challenges, researchers have developed \emph{automatic \dtask}
techniques.
Given a formal grammar for data records,
\emph{error-correcting} parsers~\cite{aho1972minimum,diekmann2020dont,parr2011ll}, can
repair nonconforming records.
The key idea in error-correcting parsers is to generate a \emph{universal grammar}
that captures \emph{all possible data-corruptions} as mutation rules
in the base grammar.
The different parses of the nonconforming data by such a universal grammar is
penalized by the number of mutation rule applications, and the parse with the
lowest penalty is chosen as the best parse.
The limitation of this approach is that it is only workable
when a formal grammar is available,
which may not always be the case in practice.
Firstly, certain data formats (e.g., CSV~\cite{taocp},
URL standard from WHATWG~\cite{whatwgurl,urldisagree}, markdown~\cite{gruber2004markdown})
may not have an official formal grammar specification, or may
have numerous incompatible standards
(e.g., markdown~\cite{gruber2004markdown}), any of which may be followed by the
parser in question. In many cases the parser may be handwritten~\cite{uncommongrammars,uncommongrammars2}, and nonconforming due to bugs or quirks,
implementing a subtly different format than the one specified.
Hence, grammar-based \dtask approaches
are suboptimal for fixing corrupt records in practice.

\input{ddmaxlimitations.tex}

When a formal specification of the data format is unavailable or unreliable,
the only viable approach is language-agnostic \dtask, as provided by lexical
\ddmax~\cite{kirschner2020debugging}. Unlike grammar-dependent methods, lexical
\ddmax does not require a formal grammar specification\footnote{From here on,
we will refer to \emph{lexical} \ddmax simply as \ddmax}.

\ddmax operates similarly to Delta Debugging~\cite{zeller2002simplifying}, but
in reverse. It requires three key components: (1) a parser to identify valid
inputs, (2) a starting minimal subsequence of the input that is \emph{valid},
and (3) the ability to add fragments ($\delta$s) to this input, resulting in
larger \emph{valid} inputs. Given these prerequisites and a corrupt record that
induces a parse error, \ddmax works as follows: (1) It identifies $\delta$s
that, when inserted into the minimal valid subsequence, avoid triggering the
parse error. (2) This process generates increasingly larger valid inputs. (3) By
isolating and removing the part of the record causing the parse error, \ddmax
minimizes data loss.

While \ddmax has proven effective in certain scenarios, it faces significant
limitations: (1) \ddmax only allows for fragment deletion ($\delta$s) as a
repair operation, which is suboptimal because corrupt records often \emph{lack
data} rather than contain extra data preventing parsing. (2) It struggles with
repairing complex corruptions involving multiple faults. (3) It requires a
\emph{valid empty record} to start from, as well as valid records as waypoints
to the maximally valid record. These constraints hinder \ddmax's ability to
achieve maximal data repair, often leading to considerable data loss.
Table~\ref{tab:ddmaxlimitations} illustrates examples where these limitations result in severe
data loss, particularly when compared to \dtask using formal specifications.

To address these shortcomings, this paper introduces \drepair, which leverages
the \emph{parse-failure feedback} that many parsers provide. This feedback
often contains crucial information about why the parse failed, which can be
used to guide the repair process. Unlike \ddmax, \drepair supports not only
deletion but also insertion and substitution as repair operations, allowing for
a more comprehensive and effective data repair process.

\drepair shares some requirements with \ddmax, such as the need to identify
valid inputs. However, it differs in two critical ways: instead of requiring a
minimal valid starting sequence and the existence of $\delta$s producing valid
inputs (which may not always be available), \drepair necessitates that the data
processor indicate whether a given nonconforming record is \emph{incomplete}
(i.e., the record fragment is a prefix of a conforming record) or
\emph{incorrect} (i.e., no suffix to this record fragment will result in a
conforming record). This feedback is typically provided by most parsers, and
when it is not, it can be obtained through external instrumentation or by
modifying the parser to provide such feedback, as demonstrated by Bj√∂rn et
al.~\cite{mathis2019parser}.

%We also emphasize that similar to \ddmax, satisfying the requirements for
%\drepair does not require using a formal grammar for parsing, and indeed, there are several
%systems that implement handwritten parsers that satisfy \drepair constraints~\cite{eaton2021parser}.

This paper makes the following
contributions:
\begin{itemize}
\item \textbf{Identifying \ddmax Limitations.}
We identify and demonstrate limitations of 
the state-of-the-art language-agnostic \ddmax algorithm, which can result in significant data loss.
\item \textbf{Relaxed Requirements.} We describe how to relax
\emph{empty passing configuration} and \emph{valid waypoints} constraints in \ddmax by leveraging parse-failure feedback.
\item \textbf{Universal Data Repair.}
We demonstrate effective \dtask using both deletions and insertions.
\item \textbf{Empirical Evaluation.} We evaluate \drepair using 656 (real-world) nonconforming
records belonging to four well-known input formats (e.g., cJSON and TinyC). 
Our results show that in comparison to \ddmax,
\drepair delivers 31\% more perfect repairs, % VERIFIEDA
delivers 2$\times$ higher-quality repairs,  % VERIFIEDB
and recovers 5.4$\times$ more data from intact records.   % VERIFIEDC

\end{itemize}

The remainder of this paper is structured as follows: 
\Cref{sec:ddmaxlimitations} highlights the limitations of the 
state-of-the-art input repair method (\ddmax).
\Cref{sec:drepair}  
describes the \drepair algorithm. We describe our research questions in
\Cref{sec:evaluation}.
We discuss the results in \Cref{sec:discussion},
related work in \Cref{sec:relatedwork}, and threats in \Cref{sec:threats}.
Finally, we conclude this paper 
with the discussion of future work in \Cref{sec:conclusion}. 



\begin{figure*}[t]
\footnotesize
\begin{boxedminipage}{\textwidth}
\smallskip
\ \begin{minipage}{1.0\textwidth}
\subsection*{Maximizing Delta Debugging Algorithm}
\medskip

Let $\test$ and $\cfail$ be given such that $\test(\emptyset) = \pass \land
\test(\cfail) = \fail$ hold.

The goal is to find $\dpass = \ddmax(\cfail)$ such that $\dpass \subset \cfail$, $\test(\dpass) = \pass$, and~$\Delta = \cfail - \dpass$ is 1-minimal.

The \emph{maximizing Delta Debugging algorithm} $\ddmax(c)$ is
\begin{align*}
\ddmax(\cfail) &= \ddmax_2(\emptyset, 2) \quad \text{where} \\
\ddmax_2(\dpass, n) &=
\begin{cases}
    %if len(minus(CX_I, cprime_y)) == 1: return cprime_y
  \textcolor{red}{\dpass} & \text{\textcolor{red}{\hphantom{else }if $|\cfail - \dpass| = 1$} (``base case$^{\textcolor{red}{a}}$'')} \\
  \ddmax_2(\cfail - \Delta_i, 2) & \parbox[t]{.45\textwidth}{else if $\exists i \in \{1, \dots, n\} \cdot \test(\cfail - \Delta_i) = \pass$ \\(``increase to complement'')} \\
\ddmax_2\bigl(\dpass \cup \Delta_i, \max(n - 1, 2)\bigr) &
\parbox[t]{.45\textwidth}{else if $\exists i \in \{1, \dots, n\} \cdot \test(\dpass \cup \Delta_i)~=~\pass $ \\(``increase to subset'')} \\
\ddmax_2\bigl(\dpass, \min(|\cfail \textcolor{red}{- \dpass}|, 2n)\bigr) & \text{else if $n < |\cfail - \dpass|$ (``increase granularity$^{\text{\textcolor{red}{b}}}$'')} \\
\dpass & \text{otherwise (``done'').}
\end{cases}
\end{align*}
where $\Delta = \cfail - \dpass = \Delta_1 \cup \Delta_2 \cup \dots \cup \Delta_n$, all
$\Delta_i$ are pairwise disjoint, and $\forall \Delta_i \cdot |\Delta_i| \approx |\cfail - \dpass| / n$
holds.

The recursion invariant (and thus precondition) for $\ddmax_2$ is
$\test(\dpass) = \pass \land n \leq |\Delta|$.\\
\textcolor{red}{a}: Bugfix: This base case is necessary to ensure that repairing JSON input \letterboxed{1*1} does not violate the invariant $n \leq |\Delta|$.\\
\textcolor{red}{b}: Bugfix: We should look for minimum of the remaining so that $n \leq |\Delta|$ is not violated
for JSON input \letterboxed{\{*"":2\}}.
\end{minipage}
\end{boxedminipage}
\caption{Maximizing Lexical Delta Debugging algorithm from Kirschner et al.~\cite{kirschner2020debugging} with corrections.}
\label{fig:ddmax}
\end{figure*}

\section{Limitations of \ddmax}
\label{sec:ddmaxlimitations}
Let us first illustrate the limitations of the state-of-the-art \dtask method (\ddmax)
 and how our approach (\drepair) addresses these limitations.
\Cref{fig:ddmax} provides the \ddmax algorithm
presented in Kirschner et al.~\cite{kirschner2020debugging}.

\subsection{\ddmax corrections}
We noticed two errors in the formal definition of
\ddmax (see \Cref{fig:ddmax}). Specifically,
(1)~\ddmax requires the base case when $|\cfail-\cpass| = 1$, where $\cfail$ is
the failing configuration, and $\cpass$ the passing configuration.
If not, \ddmax goes
into unbounded recursion on inputs such as the JSON input:
\letterboxed{1*1}. (2)~when increasing granularity, the size of the remaining
input should be considered instead of the entire text. Not doing
this would cause an invariant fail for JSON inputs such as \letterboxed{\{*"":2\}}.

\subsection{Limitations due to multiple faults}
A pattern of failure of \ddmax occurs when \ddmax is given an input with
multiple errors.  For example, consider the JSON input \letterboxed{[*]+}.
Here, the JSON string is invalid because of two invalid characters that are
non-contiguous. The operation of \ddmax (\Cref{fig:ddmax}) proceeds as follows:

\begin{enumerate}
[labelwidth=!, labelindent=20pt]
\item The operation starts with $\ddmax_2(\emptyset, 2)$
\item  $|\cfail - \emptyset| \ne 1$. Hence, the base case does not apply
\item Can we increase to complement?\\
$\cfail - \Delta_1$= \letterboxed{]+} \fail \\
$\cfail - \Delta_2$= \letterboxed{[*} \fail
\item Can we increase to subset?\\
$\emptyset \cup \Delta_1$=\letterboxed{[*} \fail \\
$\emptyset \cup \Delta_2$= \letterboxed{]+} \fail
\item Can we increase granularity? $n < |\cfail-\dpass|$ which is $2 < |\cfail-\emptyset|$ \pass \\
  Hence the next iteration is:
  $\ddmax_2\bigl(\emptyset, 4)\bigr) $
\item  $|\cfail - \emptyset| \ne 1$. Hence, the base case does not apply.
\item Can we increase to complement?\\
$\cfail - \Delta_1$= \letterboxed{*]+} \fail \\
$\cfail - \Delta_2$= \letterboxed{[]+} \fail \\
$\cfail - \Delta_3$= \letterboxed{[*+} \fail \\
$\cfail - \Delta_4$= \letterboxed{[*]} \fail
\item Can we increase to subset?\\
$\emptyset \cup \Delta_1$=\letterboxed{[} \fail \\
$\emptyset \cup \Delta_2$=\letterboxed{*} \fail \\
$\emptyset \cup \Delta_3$=\letterboxed{]} \fail \\
$\emptyset \cup \Delta_4$=\letterboxed{+} \fail
\item Can we increase granularity? $4 < 4$ \fail
\item The solution is $\emptyset$.

\end{enumerate}

That is, \ddmax is unable to optimally repair inputs of this kind which
contains multiple errors. While in this example, the data loss that occurred
may seem somewhat limited, this need not always be the case. A similar example
is given in \Cref{tab:ddmaxlimitations}.
Here, \letterboxed{\{"ABCD":[*"1,2,3,4,5,6"]*\}} contains two distinct
corruptions.
As in the previous case, \ddmax attempts to fix this input by dividing it into
smaller and smaller fragments, none of which isolates an error that when
removed. This results in the solution \letterboxed{123456} with
significant data loss, including the loss of structure and change in
input fragment type from string to number.
Hence, \ddmax cannot effectively repair such inputs containing multiple faults.

\subsection{Effect of fragment decomposition}
Unfortunately \ddmax can produce non-optimal results even when the errors are
contiguous, and hence considered \emph{single} by \ddmax. The problem happens
when the corruption in the input interacts with the fragment decomposition
algorithm of \ddmax.
As an example, consider a variant of the previous input: \letterboxed{[*+]}.
The JSON string is invalid here because it contains two invalid characters
which are contiguous.
The operation of \ddmax (\Cref{fig:ddmax}) is as follows:

\begin{enumerate}
\item The operation starts with $\ddmax_2(\emptyset, 2)$
\item  $|\cfail - \emptyset| \ne 1$. Hence, the base case does not apply
\item Can we increase to complement?\\
$\cfail - \Delta_1$= \letterboxed{+]} \fail \\
$\cfail - \Delta_2$= \letterboxed{[*} \fail
\item Can we increase to subset?\\
$\emptyset \cup \Delta_1$=\letterboxed{[*} \fail \\
$\emptyset \cup \Delta_2$= \letterboxed{+]} \fail
\item Can we increase granularity? $n < |\cfail-\dpass|$ which is $2 < |\cfail-\emptyset|$ \pass \\
  Hence the next iteration is:
  $\ddmax_2\bigl(\emptyset, 4)\bigr) $
\item  $|\cfail - \emptyset| \ne 1$. Hence, the base case does not apply.
\item Can we increase to complement?\\
$\cfail - \Delta_1$= \letterboxed{*+]} \fail \\
$\cfail - \Delta_2$= \letterboxed{[+]} \fail \\
$\cfail - \Delta_3$= \letterboxed{[*]} \fail \\
$\cfail - \Delta_4$= \letterboxed{[*+} \fail
\item Can we increase to subset?\\
$\emptyset \cup \Delta_1$=\letterboxed{[} \fail \\
$\emptyset \cup \Delta_2$=\letterboxed{*} \fail \\
$\emptyset \cup \Delta_3$=\letterboxed{+} \fail \\
$\emptyset \cup \Delta_4$=\letterboxed{]} \fail
\item Can we increase granularity? $4 < 4$ \fail
\item The solution is $\emptyset$.
\end{enumerate}

That is, this particular invalid JSON string also cannot be repaired by \ddmax.
As in the previous case, the data loss can be severe.
Consider
\letterboxed{\{\ "item":\ "Apple",\ "price":\ ***3.45\ \}} in
\Cref{tab:ddmaxlimitations} which is similar to
Kirchner et al.~\cite[Fig. 1]{kirschner2020debugging} but with an extra
\letterboxed{*}. \ddmax repairs this input to \letterboxed{\ \ \ \ 3.45},
resulting in loss of data and structure. % of information.

The issue arises from \ddmax's partitioning strategy, which fails to isolate
the error-causing fragment, even when it is contiguous.
Despite the error being localized,
no single removable fragment is identified that eliminates the error.
Consequently, \ddmax continues to search for increasingly smaller fragments,
inadvertently discarding larger portions of potentially valid data in
the process.

\subsection{Limited Ability for Correction}
\label{sec:input-synthesis}

Another major limitation of
\ddmax is that the only operation in its toolbox is \emph{deletion} of tokens.
Consider \letterboxed{\{\ "name":\ "Dave"\ "age":\ 42\ \}}.
Here, there is a missing comma. \ddmax repair of this string will
result in
\letterboxed{\ \ \ \ 42}.
The problem is that, deletion of fragments alone can lead to significant
corruption of information. In this instance, the availability of \emph{insertion}
could have repaired the input string to
\letterboxed{\{\ "name":\ "Dave",\ "age":\ 42\ \}}. Unfortunately, because
\ddmax is unable to insert any tokens, opportunities for repair can be
missed.

\subsection{Single repair-candidate}
Consider the following corrupted data \letterboxed{["A",[1,2]"]}.
Given \emph{deletion} there are two possible repair candidates here:
(1) \letterboxed{["A,[1,2]"]} and
(2) \letterboxed{["A",[1,2]]}. Either may be the correct one. However,
\ddmax is constrained to always choose just one of the canidates, and the
choice depends exclusively on which fragment was tested first.
This means that \ddmax cannot rely on a post-processing intelligent
selector such as an end-user or an automatic validator even if one is provided.

\subsection{Other limitations of \ddmax}
A final limitation of \ddmax is that it assumes that there exist a
\emph{valid passing configuration} that can be progressively \emph{extended}
to form the final
solution that is closest to the original input~\cite[Sec. 3.2]{kirschner2020debugging}.
This particular assumption may not be warranted in many real-world scenarios.
For example, consider a parser for date-time. It expects strings that follow
the format \texttt{YYYY-MM-DDTHH:MM:SSZ}. 

Given corrupt inputs such as
\letterboxed{X2024-07-23T12:34:56Z},
\letterboxed{1925X-09-13T10:14:16Z}, and
\letterboxed{1999-12-20T12:34:56ZX},
there is no ideal \emph{empty date} that \ddmax can start from, that is applicable
to all inputs even though the repair only requires deletion of characters (\letterboxed{X} here).

\begin{comment}
\subsection{Discussion}
Why does \ddmax fail to repair these inputs? A major limitation of \ddmax is
that it is modeled on \ddmin~\cite{zeller2002simplifying},
which is an effective tool for minimization of failure inducing inputs.
Given a failure inducing input, the idea of \ddmin is
to successively partition the input into smaller and smaller chunks
(a chunk is a contiguous sequence of characters), remove one
chunk at a time and check whether the remaining chunks are sufficient to
reproduce the failure. As this implies, a key assumption of \ddmin is that
we can actually remove such chunks independently. That is, if a chunk does not
contribute to the observed failure, it can be removed without affecting the
failure observed. Secondly, if multiple chunks independently cause
the same failure, only one chunk will be chosen, and minimized further.

The definition of \ddmax is a mirror of \ddmin. \ddmax starts with an empty
input that is assumed to be passing (i.e. parsable by the parser).
Then, it partitions the input into chunks, and tries to concatenate any of
these chunks to the passing input,
producing a larger passing input.
If a particular chunk fails parsing, that chunk is partitioned further,
identifying smaller chunks that can be concatenated to the passing input without causing the failure.

%The definition of \ddmax is a mirror of \ddmin. \ddmax starts with an empty
%string that is assumed to be passing (i.e. parsable by the parser).
%Then, it partitions the input into chunks,
%and tries to concatenate as any of these chunks to the passing input, producing a
%larger passing input. Any chunk that is identified as causing the failure is
%further minimized, until the smallest amount of data that should be deleted to
%remove the failure is identified and removed.
% If after dividing the input into \<n> chunks, none of the
%chunks could produce a passing input, it tries again by dividing the
%input into \<2n> (i.e., $2\times$ smaller) chunks.

As in the case of \ddmin, the \textit{unstated assumption} here is that if a chunk was
not responsible for the observed failure, it can be extracted independently of
other chunks and added to the passing input fragment without changing the
semantics. This particular \textit{assumption need not hold when we are dealing with
inputs that have a complex format}. That is, \letterboxed{"1,2,3,4,5"} is \emph{semantically}
different from \letterboxed{12345} even though a significant portion of the raw
characters from first is preserved in the second. Further, once such a
semantically changed fragment \emph{forms the seed of the passing fragment}, due to
the constraints in the input structure, the remaining fragments from the
original will likely not combine with the seed fragment, resulting in further
data loss.
%That is, once a bad but passing seed fragment forms, the semantics of

%Although \ddmax will have no problems maximizing any inputs
% \textit{if  the input processor conforms to this constraint}, we note that
% this can be a rather \textit{strong constraint in practice}.

The unfortunate issue that exacerbates this problem is that \ddmax is also
limited to only \emph{deletion} of fragments. If the corruption in the data
is due to missing tokens (which can often occur in practice because of truncation
of fields, 
%for e.g.  \letterboxed{24-07-23T12:34:56Z},), 
the only move from \ddmax is to delete more tokens, resulting in
data that passes the parser but is semantically incorrect. In common cases such
as  date and time, \ddmax cannot even attempt to repair the input because (1) there
is no ideal \emph{empty date} and (2) in common cases of corruption as
\letterboxed{20240723T12:34:56Z}, insertion of characters is required to complete
the required format.
\end{comment}
%=======
\begin{comment}
The \drepair algorithm on the other hand, follows in this fashion.
\begin{enumerate}
\item \drepair algorithm starts with the corrupted input and quickly finds the
maximal parsable prefix using a binary search: \\
\letterboxed{\{\ "name":\ "Dave"\ }.
\item At this point, \drepair applies \emph{deletion}, \emph{insertion}, or
\emph{modification} of characters in order.
In this case, the \letterboxed{"} is deleted first, resulting in: \\
\letterboxed{\{\ "name":\ "Dave"\ age":\ 42 \}}.
\item The JSON parser responds with \emph{incorrect} for this input.
\item \drepair next attempts to insert a character. Say we tried to insert
\letterboxed{1}. This results in: \\
\letterboxed{\{\ "name":\ "Dave"\ 1"age":\ 42 \}}.
\item The JSON parser responds with \emph{incorrect} for this input.
\item Indeed, only space characters and comma (\letterboxed{,}) can be
inserted here, resulting in \emph{incomplete} from the JSON parser.
\item Inserting the \letterboxed{,} results in a new input: \\
\letterboxed{\{\ "name":\ "Dave"\ ,"age":\ 42\ \}}
\item This is accepted as a valid repair.
\end{enumerate}

That is, the ability of \drepair to synthesize characters for repair can lead
to more effective repairs.
\end{comment}

\section{Repairing Data with \drepair}
\label{sec:drepair}
Our approach was motivated by the following observation.
Consider the output of processing
from \<jq>, a \<JSON> processor that is often used for processing JSON data.
%\begin{flushleft}
%                                ^
\begin{lstlisting}[xleftmargin=10pt,escapeinside={(*@}{@*)}, basicstyle=\ttfamily\small,numbers=none]
$ echo -n '{"name": "Dave" "age":42}' | jq .
(*@\textcolor{red}{parse error: Expected separator between values at line 1, column 21}@*)
\end{lstlisting}
On providing an input that contains the missing comma, the parser responds with an
\emph{approximate} location of the error.
%\end{flushleft}
If we instead provide \<jq> with a truncated input,
the parser responds with \<EOF> 
%                           ^
\begin{lstlisting}[xleftmargin=10pt,escapeinside={(*@}{@*)}, basicstyle=\ttfamily\small,numbers=none]
$ echo -n '{"name": "Dave" ' | jq .
(*@\textcolor{red}{parse error: Unfinished JSON term at EOF at line 1, column 16}@*)
\end{lstlisting}
indicating that the
input is incomplete,
and further data is required to complete the input. We observed this behavior with a variety of
parsers.
The key insight in this paper is that we can leverage this behavior to our advantage and
attempt to repair the input based on a \emph{minimal reliance} of the parser feedback.
In particular, our approach \drepair only requires that the parser is able to distinguish
between \emph{incorrect} input and \emph{incomplete} input. Given a parser that obeys this
minimal contract, we can quickly determine the location of the error, and identify the
\emph{minimal} edits required to fix the parser error.
% as we demonstrate next.

We next describe the \drepair algorithm in detail.
%As our solution is modeled on \emph{error correcting parsers}~\cite{aho1972minimum},
The following terms are used in our definition: % correspondingly:
\begin{description}[labelwidth=!, labelindent=0pt]
\item[alphabet] The set of characters that a given input string can have.

\item[string] A string is an ordered sequence of alphabets.

\item[edit] An edit is a single mutation. It can be either the deletion
or insertion of a single character.

\item[parser] A parser is an input processor that evaluates a string and returns
a response indicating whether the string is \emph{accepted} (\Rvalid), or \emph{rejected} (\Rreject).

\item[conforming parser] A conforming parser is an \emph{parser} that 
instead of just rejecting the string, specifies whether
    the string is \emph{incorrect} (\Rincorrect) or merely \emph{incomplete} (\Rincomplete), that is, a suffix exists that
will make the complete string acceptable to the parser.

\item[viable-prefix] A viable prefix is a string that when passed to the conforming parser,
 results in \Rincomplete or \Rvalid response from the parser.

\item[parse-boundary] Given a string and a conforming parser, a parse-boundary is the
length of the maximal viable-prefix. To the right of the parse-boundary is the maximal
\emph{viable-prefix} and to the left is the \emph{remaining-suffix}.

\item[repair] An \emph{edit} made to the string that extends its \emph{parse-boundary}
  or reduces the \emph{remaining-suffix}.

\item[repair-thread] A \emph{repair-thread} is a sequence of \emph{repairs} made on an
input string. A repair-thread has a single parse-boundary, a corresponding
\emph{viable-prefix}, and the \emph{remaining-suffix}.
Similarly, every parse-boundary has associated \emph{repair-threads}.
If no repairs has been made yet, it is an empty repair-thread.
A repair thread becomes a \emph{repair-candidate} when the repaired string
elicits the \Rvalid response from the parser, and there is no remaining-suffix.

\item[repair-distance] The minimal number of repairs required to transform the corrupt
string to the repair-candidate (also called \emph{edit-distance}). The larger the
repair-distance of a repair-candidate, the larger its distance from the original data.

\item[thread-queue] A priority queue of \emph{repair-threads} that is sorted by the
number of repairs applied to the viable-prefix and the parse-boundary.
\end{description}

The problem of \emph{data-repair} is as follows: Given a \emph{string} and a
\emph{parser}, find the least number of \emph{repairs} that can be made to
the string to make it acceptable by the \emph{parser}. If the parser is a
\emph{conforming parser}, the \drepair algorithm can be used to
repair the string. It has the following steps: 
%(visualized in \Cref{fig:brepair_flowchart}):

% \begin{figure}[tbp!]
% \newlength\nodedst\setlength\nodedst{.35cm}
% \newlength\ndist\setlength\ndist{.1\nodedst}
% \begin{tikzpicture}[node distance=\nodedst and 2.5\nodedst]
%     \node[blockdiagramblock] (search) {Boundary-Search};
%     \node[blockdiagramblock,right=of search] (repair) {Apply Repairs};
%     \draw[blockdiagramarrow] (search) -- (repair); %node[simpletext,pos=.5,right,font=\scriptsize] {}; % PushPQ
%     \node[blockdiagramblock,right=of repair] (extend) {Extend Boundary};
%     \draw[blockdiagramarrow] (repair) -- (extend);
%     \node[blockdiagramblock,below=of extend] (isvalid) {Check Candidates};
%     \node[simpletext,below=.3 of isvalid] (return) {\mbox{Return input}};
%     \node[blockdiagramblock,left=of isvalid] (select) {Select Threads};
%     \draw[blockdiagramarrow] (extend) -- (isvalid);
%     \draw[blockdiagramarrow] (isvalid) -- (return) node[simpletext,pos=.6,right,yshift=-.5mm] {\pass};
%     \draw[blockdiagramarrow] (isvalid) -- (select);
%     %\node[simpletext,right=.5 of isvalid.east,inner sep=1pt] (pqins1) {increase bound,\\push to PQ};
%     %\draw[blockdiagramarrow,dashed] (isvalid) -- (pqins1) node[pos=.5,above] {\pass};
%     %\node[simpletext,right=.5 of select.east,inner sep=1pt] (pqins2) {increase bound,\\push to PQ};
%     %\draw[blockdiagramarrow,dashed] (select) -- (pqins2) node[pos=.5,above] {\pass};
%     \draw[blockdiagramarrow] (select) -- (repair);
%     \pic[] at (search.south east) {numbering=1};
%     \pic[] at (isvalid.south east) {numbering=5};
%     \pic[] at (extend.south east) {numbering=3};
%     \pic[] at (repair.south east) {numbering=2};
%     \pic[] at (select.south east) {numbering=4};
%     %TODO
% \end{tikzpicture}
% \vspace*{-0.1in}
%     \caption{Work flow of \drepair}
%     \label{fig:brepair_flowchart}
%     % \vspace*{-0.1in}
% \end{figure}
% \newcommand{\refnumber}[1]{\hyperref[fig:brepair_flowchart]{Step~#1}}

\begin{algorithm}[t]
%  \footnotesize
\caption{Boundary search for \drepair}
\label{alg:bsearch}
\begin{algorithmic}[1]

  \Function{BoundarySearch}{array, parser, left=0}
    \State bound $\gets$ \Call{len}{array}

    \State right $\gets$ left + 1
    \While{right < bound $\wedge$ \Call{parser}{array[:right]} $\notin$ \{ \Rincomplete, \Rvalid\} }
        \State left $\gets$ right
        \State right $\gets$ \Call{min}{right * 2, bound}
    \EndWhile

    \If{ \Call{parser}{array[:right]} $\in \{ \Rincomplete, \Rvalid\} $} % $= \Rincomplete $}
        \State \Return right
    \EndIf

    \While{left < right - 1}
        \State middle $\gets$ (left + right) // 2
        \If{ \Call{parser}{array[:middle]} $\in \{ \Rincomplete, \Rvalid\} $}  %$= \Rincomplete $}
            \State left $\gets$ middle
        \Else
            \State right $\gets$ middle
        \EndIf
    \EndWhile
    \State \Return left
\EndFunction
\end{algorithmic}
\end{algorithm}



\begin{enumerate}
\item \emph{Boundary search.} Given any corrupt string, \drepair starts by a
  search of the input to determine the parse-boundary (\Cref{alg:bsearch}).
This is then used to construct the \emph{thread-queue} containing a single empty repair-thread,
with the parse-boundary set to the search result.

\item \emph{Apply Repair.} Starting with any existing repair-thread, \drepair applies
either a deletion or an insertion edit on the \emph{remaining-suffix}.
\begin{itemize}
\item A \emph{deletion} removes the next character in the \emph{remaining-suffix}.
This results in a new repair-thread that needs to be checked for \emph{extension} as we discuss below.
\item An \emph{insertion} inserts a character to the beginning of the \emph{remaining-suffix}.
All characters in the alphabet are considered for insertion.
Let $S^{'}$ be the viable-prefix of the current repair-thread, and $c$ be the character.
We create one repair-thread for each $c$ in the alphabet where the parser
responds with \emph{incomplete} for $S^{'}+c$, with the new viable-prefix set to $S^{'}+c$.
\end{itemize}
\item \emph{Extend Boundary.} For each repair-thread that results from the previous step,
we attempt to extend the parse-boundary by adding additional characters from the
remaining-suffix.
\item \emph{Check Candidates.} If any thread results in a
\emph{repair-candidate}, then we return the candidate.
\item \emph{Select Threads.} The algorithm chooses the best repair-thread from the priority queue,
and continues through step 2. The ordering is based on the maximum data recovered so far from the original string.
Duplicate threads (those that result in the same string) are discarded,
keeping only those with the minimal number of repairs. A response of \Rvalid is
treated same as \Rincomplete if the remaining-suffix is non-empty.
\end{enumerate}

\begin{algorithm}[t]
  %\footnotesize
\caption{\drepair Algorithm}
\label{alg:drepair}
\begin{algorithmic}[1]

\Function{DRepair}{string, parser}
    \State boundary $\gets$ \Call{BoundarySearch}{string, parser}
    \State pq $\gets$ \Call{PriorityQueue}{}
    \State \Call{add}{pq, (string, boundary, $\emptyset$)}

    \While{pq $ \neq \emptyset $ }
        \State (string, boundary, fixes) $\gets$ \Call{top}{pq}
        \State deletes $\gets$ \{(boundary, $\emptyset$)\}
        \State inserts $\gets$ \{(boundary, c) $\,|\, c \in \alpha,$ \Call{parser}{string[:boundary]+c} $\in$ \{ \Rincomplete, \Rvalid \}\}

        \For{fix \textbf{in} deletes $\cup$ inserts}
            \State new\_string $\gets$ \Call{ApplyFixes}{string, fixes + [fix]}
            \State new\_boundary $\gets$ \Call{BoundarySearch}{new\_string, parser, boundary}

            \If{\Call{parser}{new\_string[:new\_boundary]} $=$ \Rvalid $\wedge$ string[new\_boundary:] $=\emptyset$ }
                \State \Return new\_string
            \EndIf

            \State \Call{add}{pq, (string, new\_boundary, fixes + [fix])}
        \EndFor
    \EndWhile
    \State \Return $\emptyset$
\EndFunction

\end{algorithmic}
\end{algorithm}


The algorithm returns as soon as the first repair-candidate is found.
However, one may also repeatedly invoke the algorithm to produce an ordered
ranking of further repair-candidates. We have formalized this algorithm in \Cref{alg:drepair}.

\subsection{\drepair in action}
For example, let us consider the following input to the JSON processor from
Table~\ref{tab:ddmaxlimitations}:\\
\letterboxed{\{\ "name":\ "Dave"\ "age":\ 42\ \}} %We follow repair threads serially for ease of explanation.
\begin{enumerate}
\item \approach starts by executing a binary search for the boundary where the
input prefix changes from \Rincomplete to \Rincorrect. This is
obtained at index 17, providing the viable-prefix\\
\letterboxed{\{\ "name":\ "Dave"\ } and the remaining-suffix \letterboxed{"age":\ 42\ \}}
\item There are three possibilities for repair here. The first is to delete the next character
\letterboxed{"} 
from the remaining-suffix. This however, does not change the parse-boundary, as the string
\letterboxed{\{\ "name":\ "Dave"\ a} still results in \Rincorrect response from
the JSON processor. The second is to insert a character. We only insert characters that will lead
to an improvement in the parse-boundary. Here, the only possibility is
\letterboxed{,}, resulting in the string\\
\letterboxed{\{\ "name":\ "Dave"\ ,}.
\item Extending the parser-boundary by appending remaining characters in the
 remaining-suffix, we have \letterboxed{\{\ "name":\ "Dave"\ ,"age":\ 42\ \}},
  and the response \Rvalid from the JSON processor.
\end{enumerate}
%\subsection{Repair of rich inputs with \approach}
%One advantage of \approach is that it can effectively handle inputs with
Here is a second example, 
\letterboxed{\{"ABCD":[*"1,2,3,4,5,6"]*\}} again from Table~\ref{tab:ddmaxlimitations}.
We only follow one repair thread for ease of explanation.
\begin{enumerate}
\item \approach starts by finding the parse-boundary. This is
obtained at index 9, providing the viable-prefix
    \letterboxed{\{"ABCD":[} and remaining-suffix \letterboxed{*"1,2,3,4,5,6"]*\}}.
\item \approach then appends the next character \letterboxed{*} to the input,
resulting in \letterboxed{\{"ABCD":[*} %"1,2,3,4,5,6"]*\}}.
and observes the result. In this case, the JSON processor returns
\Rincorrect.
\item Hence, the newly added character is discarded, and the character at the
next index is appended, resulting in
\letterboxed{\{"ABCD":["}. %1,2,3,4,5,6"]*\}}.
This results in JSON processor responding \Rincomplete.
\item \approach now appends the character in the next index, resulting in
\letterboxed{\{"ABCD":[1"} which again results in \Rincomplete from JSON
processor.
\item Proceeding in this fashion the input reaches \\
\letterboxed{\{"ABCD":["1,2,3,4,5,6"]*} %\}}.
at which point, we again have the response \Rincorrect from the JSON
processor. Hence, we discard this character, and try the next character,
resulting in
\letterboxed{\{"ABCD":["1,2,3,4,5,6"]\}}.
\item The JSON processor responds with \Rvalid.
\end{enumerate}
This completes the repair of the given input with two repairs.
This demonstrates that \approach has no problem repairing inputs
containing multiple errors.

Let us now consider two cases where \approach has counterintuitive behavior.
Let us examine the input 
\letterboxed{\{\ "item":\ "Apple",\ "price":\ ***3.45\ \}}.
\begin{enumerate}
\item As usual, \approach starts by finding the parse-boundary, and the viable-prefix which is \\
\letterboxed{\{"item":\ "Apple",\ "price":\ }, followed by the remaining-suffix
\letterboxed{***3.45\ \}}.
 %*"1,2,3,4,5,6"]*\}}.
\item \approach Since \letterboxed{*}
is not a valid character to add, \approach deletes this character. Deletion of
the two remaining characters will result in \letterboxed{\{"item":\ "Apple",\ "price":\ 3.45\ \}},
which is accepted by the JSON processor.
\item However, we also have possible characters that can be inserted at the first parse-boundary,
which results in a parse-boundary extension. That is \letterboxed{"} will extend the parse-boundary
to \\
\letterboxed{\{"item":\ "Apple",\ "price":\ "***3.45\ \}}.
On continuation, \drepair finds that the following result with three insertions also result
in an accepted string.\\
\letterboxed{\{"item":\ "Apple",\ "price":\ "***3.45\ \}"\}}.
\end{enumerate}
That is, as \drepair operates without human intervention, it is unable to distinguish
the input semantics, which may demand different repairs.

Another example is the input \letterboxed{"abcd":[1,2,3]\}}.
\begin{enumerate}
\item \approach starts by finding the parse-boundary and the corresponding viable-prefix, which is
\letterboxed{"abcd"}.
\item The possible extensions are to delete \letterboxed{:} or to insert
one of the characters at this point. Unfortunately, none of the characters
in the alphabet can increase the parse-boundary. Hence, the only option that
is possible is to continue to delete characters from the remaining-suffix.
This leads to the string \letterboxed{"abcd"}, which is suboptimal.
\end{enumerate}

That is, \drepair can also result in suboptimal repairs.

A final example is the input \letterboxed{"[1,2,3,4]}.
\begin{enumerate}
\item \approach starts by finding the parse-boundary and the corresponding viable-prefix, which is
\letterboxed{"[1,2,3,4]}.
\item The possible extension here is to append a character \letterboxed{"},
leading to the string \letterboxed{"[1,2,3,4]"}.
%to the end of the input.
\end{enumerate}
That is, it ignores the possibility of deletion of the first character as the
correction even though that can lead to an optimal repair-candidate.

We next discuss possible mitigation strategies to address these issues.

\subsection*{Extended \drepair}
%\drepair is an effective approach to input repair, but has a few blind spots.
%In this section, we discuss how we can mitigate these blind spots.

When \drepair obtains an \Rincomplete or \Rvalid
response from the parser, it assumes that there can be no repairs in the viable-prefix
thus obtained.
However, as we saw in the previous section, this need not be the case. For example, 
given \letterboxed{"abcd":[1,2,3]\}}, the parser returns \Rvalid for the string
\letterboxed{"abcd"}. However, as we found, a repair inserting \letterboxed{\{} in
the beginning of the string, resulting in \letterboxed{\{"abcd":[1,2,3]\}}
can lead to more data recovery.
To allow such repairs to take place, we extend the \drepair potential candidates in the following fashion.

When \drepair obtains an \Rincorrect response from the parser, we create repair-candidates not only
at the end of the viable-prefix, but also at all points in the viable-prefix. That is, given
the corrupt string, \letterboxed{"abcd":[1,2,3]\}}, when we obtain \Rincorrect with \letterboxed{"abcd":},
all the following locations indicated by red cursors are candidate locations for inserts;
\begin{enumerate*}
  \item \letterboxedC{red}{\uline{\,}}\letterboxed{"abcd":[1,2,3]}
  \item \letterboxed{"}\letterboxedC{red}{\uline{\,}}\letterboxed{abcd":}
  \item \letterboxed{"a}\letterboxedC{red}{\uline{\,}}\letterboxed{bcd":}
  \item \letterboxed{"ab}\letterboxedC{red}{\uline{\,}}\letterboxed{cd":}
  \item \letterboxed{"abc}\letterboxedC{red}{\uline{\,}}\letterboxed{d":}
  \item \letterboxed{"abcd}\letterboxedC{red}{\uline{\,}}\letterboxed{":}
  \item \letterboxed{"abcd"}\letterboxedC{red}{\uline{\,}}\letterboxed{:}
\end{enumerate*}.
Similarly, each character next to the red cursor becomes a potential candidate for deletion.
The problem with this approach is that it may lead to numerous repair-candidates, with each
location potentially having multiple candidates. That is, if we have $n$ alphabets in the language,
then each location can at worst produce $n+1$ candidates, and a viable-prefix of length $l$ can
result in $l\times (n+1)$ candidates. Hence, heuristic strategies are needed to
reduce the number of repair-candidates. Such heuristics may be program or data specific.
%One such heuristic is to only choose those characters that allow us to extend the parsing-boundary
%beyond the current \Rincorrect response, or in the case of \Rincomplete response, to produce
%a valid string. 
In our current empirical evaluation, we only use the simple \drepair, with no additional extensions.
However, additional heuristics will be one of the possible directions of further research.

\subsection{Postprocessing}
\drepair can generate multiple repair-candidates, only one of which may be
acceptable. For example, while \drepair may generate both
\<\{"item": "Apple", "price": "***3.45 \}"\}> as well as \<\{"item": "Apple", "price": "***3.45 \}"\}>,
only one may be correct. Hence, we provide a ranked list
of repair-candidates (ordered by repair-distance) to the user, and rely on
user-defined post-processing to identify the best candidate.

Similarly,
\drepair can synthesize tokens that lets the parse continue, and produce
complete valid records. However, tokens thus produced are do not hold semantic information.
Hence, during post-processing, we expect to replace synthesized data with
semantic content with placeholders as provided by the user.
%Postprocessing is necessarilty program and data specific.

\section{Evaluation}
\label{sec:evaluation}
Where does \drepair stand compared to the state-of-the-art? In this section, we
propose the following research questions which are designed to investigate the
effectiveness of \drepair in multiple dimensions.

\subsection{Research Questions}
% What is the effectiveness of \drepair as compared to the state-of-the-art?
The primary dimension in \dtask is whether the data can be recovered at all.
That is, it should result in repaired data records which are accepted by the
program. If the program does not accept the data, then the entire record
is lost.
Hence, we ask:

\noindent\textbf{RQ1: How many corrupt records can be repaired by \drepair and its competitors?}
To answer this question, we consider both real-world as well as synthetically
introduced corruptions, and check how many of the corrupt records can be
recovered.
% Answering this question allows us to understand whether
%\drepair can form an alternative to the state-of-the-art techniques.

The second dimension of effectiveness of \dtask is the \emph{quality of repair}.
A repair-candidate is high quality if the number of repairs needed is small,
when compared to another repair-candidate with a larger number of steps.
Hence, we ask:

\noindent\textbf{RQ2: What is the quality of \dtask by \drepair and its competitors?}
Answering this question allows us to understand the quality of repairs
performed by \drepair.

While effectiveness is important, one should also be concerned about efficiency.
That is, while it is expected that a more intelligent algorithm may take more
runtime, it should be within practical bounds. Hence, the third research
question concerns the efficiency of the approach.

\noindent\textbf{RQ3: How fast is \drepair compared to the state-of-the-art?}
Answering this question allows us to evaluate the practicality of \drepair.


\subsection{Subject Programs} %As subjects w
%\begin{filecontents*}{subjectprograms.tex}
\begin{table}[!tbp]\centering
\caption{Subject programs used in the evaluation}
\begin{tabular}{|p{4cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|}
\hline
\textbf{} & \textbf{INI} & \textbf{cJSON} & \textbf{TinyC} \\
\hline
\textbf{LOC} & 382 & 3062 & 375\\
\textbf{Lang.} & C & C & C \\
\textbf{1st Commit} & 2009 & 2009 & 2011\\
\textbf{Last Commit} & 2022 & 2022 & 2018\\
\hline
\end{tabular}
\label{tab:subjectprograms}
\end{table}
%\end{filecontents*}

We used three data formats and their corresponding programs (\Cref{tab:subjectprograms}). These are INI (INI), JSON (cJSON), and TinyC (TinyC). Each program is moderately large (between 300 LOC to 3000 LOC), relatively mature (7 to 14 years of development), and written in \<C>.

\subsection{Test Data} 

% 806 - SExp  (150) = 656
We evaluate our approach using 656 corrupt files.
For our empirical-evaluation, we use one data-record per file. Hence, we use
the terms \emph{file}, and \emph{record}, interchangeably in our evaluation.
However, note that many real world formats can have multiple records per file.
As test data, we crawled a large corpus of real-world files
from GitHub~\cite{githubapi}, from which we identified corrupt files. 

While the real-world corrupted data provides a useful metric for comparison,
we do not know what the intact (non-corrupt) data should be. Hence,
for each format, we also introduced a set of 100 artificially corrupted
files from 50 randomly selected valid real-world files.
Half of these corrupted files contain a single mutated byte and the other half
contains multiple (2 to 16) mutated bytes.
Each mutation was randomly chosen to be either be a byte-flip, an insertion or a
deletion to resemble real-world corruptions such as bit-rot on hard disks,
transmission errors in network protocols, and human entry error.
\Cref{tab:inputdetails} provides the details.

%\input{inputdetails.tex}
%\begin{filecontents*}{inputdetails.tex}
\begin{table}[!tbp]\centering
\caption{Details of Corrupt Files}
\begin{tabular}{|p{4cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|}
\hline
&  \multicolumn{3}{c|}{\textbf{Number of Corrupt Files}}  \\
\textbf{Type of Corrupt File} & \textbf{INI} & \textbf{cJSON} & \textbf{TinyC} \\
\hline
\textbf{Real-World Files} & 101 & 107 & 148 \\
\textbf{Single Mutation} & 50 & 50    & 50 \\
\textbf{Multiple Mutations} & 50 & 50 & 50 \\
\hline
\textbf{Total } (656) & 201 & 207    & 248 \\
\hline
\end{tabular}
\label{tab:inputdetails}
\end{table}
%\end{filecontents*}

\subsection{Baseline Comparisons}
In this work, we compare the performance of \drepair to several repair
techniques as follows:\\

\noindent{\textbf{\Formatfree}.}
As \drepair does not require the format-specification to repair data, we
need to compare it to similar techniques that do not require a
format-specification. These are our baselines.
\begin{description}[wide]
\item[\textbf{(1) Basic:}]
  We leverage the built in error correction in the subject programs as was 
  used by Kirschner et al.~\cite{kirschner2020debugging} as an initial
  baseline. Note that this is not a repair technique, as no correction to
  the data is made.

\item[\textbf{(2) Lexical \ddmax:}] As the second baseline, we compare the
  \emph{\formatfree} lexical \ddmax described by Kirschner et al.~\cite{kirschner2020debugging}.
    This is the previous state-of-the-art when compared to \drepair (which is
    also \formatfree).
\end{description}


\noindent{\textbf{\Formatdependent}.}
While \drepair is designed to use when the formal data-specification is not
available, one may still ask. How does \drepair perform when compared to the
data-format specification based techniques when such a formal specification
is available.

\begin{description}[wide]
\item[\textbf{(3) ANTLR:}] We use ANTLR as the first baseline \formatdependent
  technique for comparison. Note that this is just the number of invalid records
  which are repaired by ANTLR builtin error recovery strategy~\cite{parr2013definitive},
  allowing the input to be accepted even under errors. That is, there is no
  \emph{\dtask} performed.

\item[\textbf{(4) Syntactic \ddmax:}] The syntactic \ddmax uses the
  grammar specification to parse the incoming data, and leverages the parse
  tree thus obtained for data-repair.
  This was also described by Kirschner et al.~\cite{kirschner2020debugging}.
\end{description}

\subsection{Platform}
All experiments were conducted
on an ASRock X470D4U with six physical CPU cores and 32GB of RAM, with an AMD Ryzen 5600X @ 3.70GHz, 12~virtual cores, running Debian GNU/Linux.


\subsection{Research Protocol}
We run each repair technique on each file and collect the repair metrics.
We found that four minutes is a sufficient time budget to evaluate all
techniques on most inputs, and a longer timeout did not result in a
significant increase in repairs for all techniques. Hence, we used four
minutes as the timeout for repair.


% \section{Results}
% \label{sec:results}
% This section describes the findings of our empirical evaluation.
% 
% \noindent\textbf{RQ1: How many corrupt records can be repaired by \drepair?}
% The repair effectiveness for \formatfree and \formatdependent
% methods on corrupt data records containing both real-world as well as
% synthetically introduced corruption are tabulated in
% \Cref{tab:effectiveness}.
% 
% \noindent\textbf{RQ2: What is the average number of repair steps required for \dtask by \drepair?}
% The repair quality in terms of repairs required for the best repair-candidate is
% tabulated in \Cref{tab:datarepairquality}. Note neither Basic nor ANTLR
% result in actual data-repair, but error-recovery. Hence, we only tabulate the
% repairs from \ddmax variants.
% 
% \noindent\textbf{RQ3: How fast is \dtask compared to the state-of-the-art?}
% For a balanced evaluation, we analyse a set of 330 invalid inputs
% that were completely repaired by all three approaches within the four minutes timeout.
% \Cref{tab:efficiency}
% reports the efficiency of all three approaches.
%\begin{filecontents*}{.datarepairquality.tex}

\section{Results and Discussion}
\label{sec:discussion}
\noindent\textbf{RQ1: How many corrupt records can be repaired by \drepair?}
% \noindent\textbf{RQ1: How many corrupt records can be repaired by \drepair?}
% The repair effectiveness for \formatfree and \formatbased
% methods on corrupt data records containing both real-world as well as
% synthetically introduced corruption are tabulated in
% \Cref{tab:effectiveness}.
This experiment compares the number of files repaired by \drepair with both
\emph{\formatfree} and \emph{\formatdependent}
techniques. The results are tabulated in \Cref{tab:effectiveness}.
%In this experiment, we measure the total number of files repaired by \drepair in
%comparison to both \emph{\formatfree} 
%and \emph{\formatdependent}  \dtask techniques. 
%These results are visualized in \Cref{fig:effectiveness}.
%\drepair is effective in repairing corrupt records. 
Overall, \drepair repaired 77\% of corrupt data (503 out of 656).
Notably, \drepair performed better than syntactic \ddmax (next best)
for cJSON, and TinyC, while it performed slightly worse for INI.
%Our analysis of INI repaired files highlights a limitation of
%\drepair---if the corruption does not trigger a parse
%error immediately, the effectiveness naive \drepair suffers.

%\input{.effectivenessnogrammar.tex}

%\begin{filecontents*}{.effectivenessnogrammar.tex}
\begin{table}[!tbp]
\centering
  \caption{Repaired corrupt records. The \textbf{Improvement} is the difference between \drepair and \ddmax.}
%\begin{subtable}{\textwidth}
%\centering
%  \caption{For \textbf{\formatfree} \dtask approaches.}
\begin{tabular}{|p{4.0cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|}
\hline
&  \multicolumn{4}{c|}{\textbf{Number of Repaired Records}}  \\
&  \multicolumn{1}{c|}{\textbf{ALL}} & \multicolumn{3}{c|}{\textbf{Data Format}}  \\
\textbf{Techniques} & \textbf{Total} \textbf{(\%)} & \textbf{INI} & \textbf{cJSON} & \textbf{TinyC} \\
\hline
\textbf{Basic}   & 33 (5\%) & 27	 & 6 &	0\\
\textbf{Lexical \ddmax} & 447 (68\%) & \textbf{201}  & 132  & 114  \\ 		
\hline
\textbf{ANTLR} & 248 (38\%) & 133 & 69 & 46   \\
\textbf{Syntactic \ddmax} & 465 (71\%) & \textbf{201}  & 144  & 120  \\ 	
\hline
\textbf{\approach}  & \textbf{503} (\textbf{77\%}) & 191 & \textbf{158}  & \textbf{154} \\
\hline
 \textbf{Impr. over Lex. \ddmax} &  \textbf{9\%}  & $-$5\% & \textbf{20\%} & \textbf{35\%} \\
% \hline
  \textbf{Impr. over Syn. \ddmax} &  \textbf{6\%}  & $-$5\% & \textbf{10\%} & \textbf{28\%} \\
\hline
\end{tabular}
\label{tab:effectiveness}
%\end{subtable}
\end{table}
%\end{filecontents*}

%\input{.effectivenessgrammar.tex}

% \begin{figure}[!tbp]\centering
% \centering
% \pgfplotstableread{
% Label      INI    cJSON    TinyC
% Basic   27     6        0
% ANTLR      133    69       46
% Lex.ddmax  201    132      114
% Syn.ddmax  201    144      120
% DRepair     191    158     154
%     }\effectivenessdata
% \begin{minipage}{.45\textwidth}
% \begin{tikzpicture}
% \begin{axis}[
%     ybar stacked,
%     ymin=0,
%     ymax=750,
%     xtick=data,
%     bar width=25,
%     legend style={cells={anchor=west}, legend pos=north west},
%     reverse legend=true,
%     xticklabels from table={\effectivenessdata}{Label},
%     xticklabel style={text width=2cm,align=center,font=\footnotesize},
%     xtick style={draw=none},
% ]
%     \addplot [fill=darkgray] table [y=INI, meta=Label, x expr=\coordindex] {\effectivenessdata};
%     \addlegendentry{INI}
%     \addplot [fill=gray] table [y=cJSON, meta=Label, x expr=\coordindex] {\effectivenessdata};
%     \addlegendentry{cJSON}
%     \addplot [fill=white,nodes near coords,point meta=y] table [y=TinyC, meta=Label, x expr=\coordindex] {\effectivenessdata};
%     \addlegendentry{TinyC}
% \end{axis}
% \end{tikzpicture}
% \end{minipage}
% \caption{Number of files repaired by each approach}
% \label{fig:effectiveness}
% \end{figure}

\begin{table}[!tbp]
\caption{Repair effectiveness (Levenshtein distance) between corrupt data and repaired data.}
%The best data repair in bold.}
\begin{tabular}{|p{4.0cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|}
\hline
 &  \multicolumn{4}{c|}{\textbf{Average Repair Distance}}  \\
&  \multicolumn{1}{c|}{\textbf{ALL}} &   \multicolumn{3}{c|}{\textbf{Data Format}}  \\
\textbf{Techniques} & \textbf{Average}  & \textbf{INI} & \textbf{cJSON} & \textbf{TinyC} \\
\hline
\textbf{Lex. \ddmax} & 26.4 & {10.2} &  61.6 &  7.5 \\
\textbf{Syn. \ddmax} & 124.7 &  258.1 & 82.7 &  33.3 \\
\hline
\textbf{\approach} & \textbf{13.2}  & \textbf{9.5} &  \textbf{28.7} & \textbf{1.6} \\
\hline
\textbf{Impr. over Lex. \ddmax} & \textbf{2$\times$} & \textbf{1.1$\times$} & \textbf{2.1$\times$} & \textbf{4.7$\times$} \\
\textbf{Impr. over Syn. \ddmax} & \textbf{9.4$\times$} & \textbf{27.2$\times$} & \textbf{2.9$\times$} & \textbf{20.8$\times$} \\
\hline
\end{tabular}
% \hline
\label{tab:datarepairquality}
\end{table}
%\end{filecontents*}

%\input{.datarepairquality.tex}
%\input{.efficiency.tex}


% For example, consider the JSON nested list \letterboxed{[[[]]]}.
% Introducing a quote--a possible corruption---can result in \letterboxed{[[["]]]}.
% However, \drepair is unable to correctly identify the error because
% feeding \letterboxed{[[["]]]} to the parser results in \Rincomplete.
% Hence, \drepair will attempt to fix this corruption by appending
% more characters to the record. This induces the next problem:
% Given \letterboxed{[[["]]]}, it now needs to generate three close
% parenthesis before the parser returns \Rvalid.
% Assuming say $n$ characters in the alphabet, and assuming
% that any of the characters is a possible continuation, only one out of
% $n^3$ repair threads would produce \letterboxed{)))} in the next three
% insertions. Tracking these many repair threads affects the runtime of the
% algorithm, and leads to a timeout.
% 
% We note that, while this is a limitation, this can be worked around by
% enabling the extended \drepair at the cost of a much higher runtime or
% limiting \drepair repairs to \emph{deletions} at the cost of a smaller
% repertoire of repairs.

%In INI also, we find a similar issue, with corruptions not immediately signaling
%a parse-error.

We note that \drepair outperforms even the \emph{\formatdependent} \dtask approaches
in overall performance despite zero knowledge of the format
(\Cref{tab:effectiveness}).
% \noindent\emph{Unique repairs:} 
% To gain deeper insights into the behavior of the \drepair and \ddmax algorithms,
% we examined whether certain corruptions could be repaired \emph{exclusively} by one
% algorithm and identified cases where specific records could not be repaired by
% some algorithms, while all others successfully repaired them.
% Our findings are presented in \Cref{fig:repaircomplementarity}.
% 
% We found that about 10\% of records could only be repaired by \drepair,
% in comparison to 2\% for lexical \ddmax, and 4\% for syntactic \ddmax.
% Overall, we find that a hybrid approach combining all three could perform
% slightly better (6\%) than \drepair.


\begin{result}
\drepair repairs more records than both lexical and syntactic \ddmax.
It repaired 9\% more records than lexical \ddmax (closest), and was
up to 35\% better than lexical \ddmax for TinyC.
\end{result}

\noindent\textbf{RQ2: What is the quality of \dtask by \drepair and its competitors?}
% \noindent\textbf{RQ2: What is the average number of repair steps required for \dtask by \drepair?}
% The repair quality in terms of repairs required for the best repair-candidate is
% tabulated in \Cref{tab:datarepairquality}. Note neither Basic nor ANTLR
% result in actual data-repair, but error-recovery. Hence, we only tabulate the
% repairs from \ddmax variants.
To answer this question, we collected all corrupt data-records that could be
successfully repaired. Next, for each pair, we computed the Levenshtein distance
between the corrupt record and the repaired record. This is given in
\Cref{tab:datarepairquality}.
%\Cref{tab:datarepairquality} presents the repair effectiveness of each technique.
%We calculated the Levenshtein distance between repaired and corrupt files
%from 327 fully repaired files.
\drepair achieved an average of 13.2 edits,
which is \emph{2$\times$ fewer} than
lexical \ddmax, which is the next best. % VERIFIEDB


\noindent\textbf{Detailed Evaluation of Repair Quality:}
While measuring the edit-distance from corrupted data to repaired data is a
reasonable measure of quality of repair, it overlooks an important facet
of data-repair. That is, in most circumstances, a corrupt data record is likely
to have originated from an intact one, and the repair quality should be judged
not just by the number of operations it took to make the data-record valid, but
also by the how close the repaired data is to the original data.

While edit-distance is a useful metric for evaluating repair quality,
it overlooks a crucial aspect of data recovery: The repaired record
should be as close as possible to the original record.
To evaluate this, we start with the synthetically corrupted records.
To ensure that we evaluate similar data, we choose single character
corruptions.

The edit-distance between intact records and their repairs from the competing
techniques are given in \Cref{tab:validtorepaired}. A related question 
is how many repair steps it took to move from corrupt to corrected. This
is given in \Cref{tab:invalidtorepaired}.

% bRepair INI 							1	8.38	7.64	0.32	0.44	0.18
% bRepair JSON							1	6.69	6.81	0.30	4.44	4.48
% bRepair TinyC							1	0.96	1.42	0.16	0.62	0.94
% 
% 
% DDMax	INI								1	9.12	8.48	0.32	2.26	2.08
% DDMax	JSON							1	24.74	24.52	0.3		24.42	24.4
% DDMax	TinyC							1	2.94	3.16	0.16	2.94	3.16
% 
% DDMaxG	INI								1	293.24	293.02	0.32	262.9	262.84
% DDMaxG	JSON							1	183.08	183.18	0.3		183.02	183.06
% DDMaxG	TinyC							1	38.12	38.2	0.16	11.38	11.38
% 
% Antlr	INI								1	287.66	287.26	0.32	256.18	256.04
% Antlr	JSON							1	127.22	127.3	0.3		126.58	126.62
% Antlr	TinyC							1	40.48	40.44	0.16	0.24	0.2

\begin{table}[!tbp]
\centering
\caption{Distance from valid to repaired 1 character corruption}
\begin{tabular}{|p{4.0cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|}
\hline
\textbf{Techniques} & \textbf{INI} & \textbf{JSON} & \textbf{TinyC} & \textbf{Average} \\
\hline
Antlr & 287.66 & 127.22 & 40.48 & 151.79 \\
Lex. \ddmax & 9.12 & 24.74 & 2.94 & 12.27 \\
Syn. \ddmax & 293.24 & 183.08 & 38.12 & 171.48 \\
\drepair & 8.38 & 6.69 & 0.96 & 5.34 \\
\hline
\end{tabular}
\label{tab:validtorepaired}
\end{table}

\begin{table}[!tbp]
\centering
\caption{Distance from invalid to repaired 1 character corruption}
%\begin{tabular}{|p{4cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|}
\begin{tabular}{|p{4.0cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|}
\hline
\textbf{Techniques} & \textbf{INI} & \textbf{JSON} & \textbf{TinyC} & \textbf{Average} \\
\hline
Antlr & 287.26 & 127.30 & 40.44 & 151.67 \\
Lex. \ddmax & 8.48 & 24.52 & 3.16 & 12.05 \\
Syn. \ddmax & 293.02 & 183.18 & 38.20 & 171.47 \\
\drepair & 7.64 & 6.81 & 1.42 & 5.29 \\
\hline
\end{tabular}
\label{tab:invalidtorepaired}
\end{table}

As these two tables show, \drepair was able to repair the corruption with the
minimal loss of data compared to the state-of-the-art.


\begin{result}
\drepair achieves significantly better repair quality, requiring 2$\times$
fewer edits than its closest competitor, lexical \ddmax.
Additionally, \drepair demonstrates a higher data recovery rate, recovering
5.4$\times$ more data on average than its nearest competitor, lexical \ddmax.
\end{result}

We investigated why \drepair was unable to find the single
character fix. We found that it was because the corruption did not immediately
trigger a parse error. To illustrate,
consider the JSON nested list \letterboxed{[[[]]]}.
Introducing a quote--a possible corruption---can result in \letterboxed{[[["]]]}.
However, \drepair is unable to correctly identify the error because
feeding \letterboxed{[[["]]]} to the parser results in \Rincomplete.
Hence, \drepair will attempt to fix this corruption by appending
more characters to the record, which is not the minimum fix.
%This induces the next problem:
%Given \letterboxed{[[["]]]}, it now needs to generate three close
%parenthesis before the parser returns \Rvalid.
%Assuming say $n$ characters in the alphabet, and assuming
% that any of the characters is a possible continuation, only one out of
% $n^3$ repair threads would produce \letterboxed{)))} in the next three
% insertions. Tracking these many repair threads affects the runtime of the
% algorithm, and leads to a timeout.

We note that, while this is a limitation, this can be worked around by
enabling the extended \drepair at the cost of a much higher runtime or
limiting \drepair repairs to \emph{deletions} at the cost of a smaller
repertoire of repairs.

Another key question is how much of the original data remains. This can
be answered by counting how many \emph{delete} operations were used on average.
This is given in \Cref{tab:delops}, which shows that \drepair achieves
the minimal data loss, about 1.83 characters on average per repair. This
is 5.4$\times$ fewer than the next best competitor Lexical \ddmax.

\begin{table}[h]
\centering
\caption{Count of deletions from valid to repaired}
\begin{tabular}{|p{4.0cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|}
\hline
\textbf{Technique} & \textbf{INI} & \textbf{JSON} & \textbf{TinyC} & \textbf{Average} \\
\hline
Antlr & 256.18 & 126.58 & 0.24 & 127.67 \\
Lex. \ddmax & 2.26 & 24.42 & 2.94 & 9.87 \\
Syn. \ddmax & 262.90 & 183.02 & 11.38 & 152.43 \\
\drepair & 0.44 & 4.44 & 0.62 & 1.83 \\
\hline
\end{tabular}
\label{tab:delops}
\end{table}


% %\begin{filecontents*}{.datarecovery.tex}
% \begin{table*}[!tbp]\centering
% \caption{Quality of repair as edit-distance between intact and repaired records}
% \begin{tabular}{|p{4.0cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|}
% \hline
%  &  \multicolumn{4}{c|}{\textbf{\% Data Recovered by Approach}} \\
% &  \multicolumn{1}{c|}{\textbf{ALL}} & \multicolumn{3}{c|}{\textbf{Data Format}}  \\
% \textbf{Techniques} & \textbf{Average} & \textbf{INI} & \textbf{cJSON} & \textbf{TinyC} \\
% \hline
% \textbf{Lexical \ddmax} & 81\%  & 85.8\% & 82.2\%   & 47.7\% \\
% \textbf{Syntactic \ddmax} & 74\%  &  70.6\% & 81.5\%  & 47.0\% \\
% \hline
% \textbf{\approach} & \textbf{91\%}  &  \textbf{85.9\%} & \textbf{98.5\%} & \textbf{82.1\%} \\
% \hline
% \textbf{Impr. over Lex. \ddmax} & 12\% &  0.1\%  & \textbf{19.8\%} & \textbf{72.1\%} \\
% \textbf{Impr. over Syn. \ddmax} & \textbf{23\%}  &  \textbf{21.6\%}  & \textbf{20.8\%} & \textbf{74.7\% }  \\
% \hline
% \end{tabular}
% \label{tab:datarecovery}
% \end{table*}
% %\end{filecontents*}

% The results indicate that \drepair recovered an average of 91\% of the input
% data, which is 23\% more than the best baseline competitor, lexical \ddmax.
% Across all input formats, \drepair recovered up to 75\% more data than both
% \ddmax variants.
% These findings demonstrate that \drepair is more effective at recovering valid
% data compared to both lexical and syntactic \ddmax.

% \begin{figure}[!tbp]
% \centering
% \caption{\centering
% Venn Diagram showing the number of invalid inputs repaired (solely) by a (combinations of) technique(s) %, or the combination of approaches
% }
% \begin{minipage}[b]{0.45\textwidth}
%     \centering
%     \begin{tikzpicture}[circ/.style={draw=black,line width=1pt,fill=none,shape=circle,minimum width=2.5cm,minimum height=2.5cm},lbl/.style={font=\bfseries}]
%         \node[draw=none,minimum width=1.5cm,minimum height=1.29904cm,inner sep=0,outer sep=0] at (0,0) (anchor) {};
%         \node[circ] at (anchor.south west) (g1) {};
%         \node[circ] at (anchor.south east) (g2) {};
%         \node[circ] at (anchor.north) (g3) {};
%         \node[lbl,anchor=north] at (g1.south) {\ddmax};
%         \node[lbl,anchor=north] at (g2.south) {\ddmaxg};
%         \node[lbl,anchor=south] at (g3.north) {\drepair};
%         \node[lbl] at ($(g1)!0.5!(g2) - (0,.4)$) {53};
%         \node[lbl] at ($(g2)!0.5!(g3) + (.2,.2)$) {50};
%         \node[lbl] at ($(g1)!0.5!(g3) + (-.2,.2)$) {25};
%         \node[lbl] at ($(anchor.center) - (0,.2)$) {488};
%         \node[lbl] at ($(g1.center) - (.2,.1)$) {12};
%         \node[lbl] at ($(g2.center) - (-.2,.1)$) {23};
%         \node[lbl] at ($(g3.center) + (0,.2)$) {61};
%     \end{tikzpicture}
% \end{minipage}
% \label{fig:repaircomplementarity}
% \end{figure}


%\input{.datarecovery.tex}

\noindent\textbf{Perfect repair.} While data recovery metrics offer some insight
into the quality of repairs, the key question remains: does the repair fully and
accurately restore the corrupted data?
Since we introduced the corruptions synthetically, we can directly investigate
this.

We evaluated the number of files perfectly repaired by each approach, meaning
the repaired file is \emph{identical} to its state before corruption.
This experiment used only synthetically corrupted records.

\begin{table}[!tbp]\centering
\caption{Number of \textit{perfectly} repaired files for \approach in comparison to \ddmax and \ddmaxg
}
\begin{tabular}{|p{4.0cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|}
\hline
\textbf{Techniques}&  \textbf{INI}&\textbf{cJSON} &\textbf{TinyC}&\textbf{Total}  \\
\hline
\textbf{Antlr}  & 0 & 21 & 0 & 21 \\
\textbf{Lex. \ddmax}  & 1 & 14 & 18 & 33 \\
\textbf{Syn. \ddmaxg} & 0 & 1  & 0  & 1  \\
\hline
\textbf{\approach} &  1 & 21  & 26 & 48  \\
\hline
\end{tabular}
\label{tab:perfectrepairs}
\end{table}

As shown in in \Cref{tab:perfectrepairs},
\drepair achieved 31\% more perfect repairs than lexical \ddmax.
%VERIFIEDA

% We also analyzed files that were exclusively repaired by \drepair, \ddmax, or
% both, as illustrated in \Cref{fig:perfectlyrepairedvenndiagram}.
% The figure shows that 36 files were perfectly repaired by both \drepair and
% lexical \ddmax.
% Notably, \drepair repaired 2.17$\times$ more files than lexical \ddmax on its own.

\begin{result}
\drepair completed 31\% more perfect repairs than lexical \ddmax.
\end{result}


\noindent\textbf{RQ3: How fast is \dtask compared to the state-of-the-art?}
% \noindent\textbf{RQ3: How fast is \dtask compared to the state-of-the-art?}
% For a balanced evaluation, we analyse a set of 330 invalid inputs
% that were completely repaired by all three approaches within the four minutes timeout.
% \Cref{tab:efficiency}
% reports the efficiency of all three approaches.
The runtime of all three approaches is shown in \Cref{tab:efficiency}.
Syntactic \ddmax is the fastest, with an average runtime of 2 seconds and
requiring around 2000 program runs per repair.
In comparison, \drepair is approximately five times slower than syntactic
\ddmax and three times slower than lexical \ddmax.

The primary reason for the increased runtime in \drepair is the additional
insert repair operation, where each character in the alphabet needs to be
checked. This process can be time-consuming, especially in formats with
large alphabets.
Despite being slower, \drepair's average runtime of 10 seconds remains practical
for \dtask.

\begin{result}
Although \drepair is slower than \ddmax, its average runtime of 10 seconds is
still practical for \dtask.
\end{result}

% \begin{figure}[!tbp]\centering
% \caption{\centering Venn Diagram showing the 
% %overlap of 
% files that were \textit{perfectly} repaired (\textit{solely}) by \approach,  \ddmax or both approaches. 
% }
% \centering
% \begin{minipage}[b]{0.45\textwidth}
%     \centering
%     \begin{tikzpicture}[circ/.style={draw=black,line width=1pt,fill=none,shape=circle,minimum width=2.0cm,minimum height=2.5cm},lbl/.style={font=\bfseries}]
%         \node[draw=none,minimum width=1.5cm,minimum height=1.29904cm,inner sep=0,outer sep=0] at (0,0) (anchor) {};
%         \node[circ] at (anchor.south west) (g1) {};
%         \node[circ] at (anchor.south east) (g2) {};
%         \node[lbl,anchor=north] at (g1.south) {\strut\ddmax};
%         \node[lbl,anchor=north] at (g2.south) {\strut\approach};
%         \node[lbl] at ($(g1)!0.5!(g2) - (0,.1)$) {36};
%         \node[lbl] at ($(g1.center) - (.2,.1)$) {6};
%         \node[lbl] at ($(g2.center) - (-.2,.1)$) {13};
%     \end{tikzpicture}
% \end{minipage}
% \vspace{-0.4cm}
% \label{fig:perfectlyrepairedvenndiagram}
% \end{figure}
%\end{comment}

%\subsection{RQ5 Quality of Repaired Files}
%\todo{EZ: Write RQ5}
Our evaluation shows that \drepair is able to outperform 
\dtask even while significantly relaxing the constraints placed on the parser.
That is, while \ddmax requires an empty valid input to start from, and the
existence of valid waypoints allowing one to construct a path to the final
repair fragment by fragment, \drepair only requires the parser to tell us when
the parse-error was encountered, and its kind.


%\begin{filecontents*}{.efficiency.tex}
\begin{table}[!bp]\centering
\caption{Efficiency of \approach vs. \ddmax. 
%  lowest runtime and smaller number of program runs %and significant \% improvement in efficiency
%are in \textbf{bold}. %, second-best time performance is in \textit{italics}
}
\begin{tabular}{|l | r | r |}
\hline
%&  \multicolumn{2}{c|}{\textbf{Runtime (s)}} & \multicolumn{2}{c|}{\textbf{\#Prog. Runs}}  \\
\textbf{Techniques} %& \textbf{Inputs}
&  \textbf{Avg. Runtime}  & \textbf{Avg. Runs}  \\
\hline
\textbf{Lex. \ddmax} & 3.4 & 3260 \\
\textbf{Syn. \ddmax} & \textbf{2.0} & \textbf{2075}  \\
\textbf{\approach} &  10.2 & 11537 \\
\hline
\end{tabular}
\label{tab:efficiency}
\end{table}
%\end{filecontents*}

\subsection{Limitations of \drepair}
While \drepair is an improvement over the state of the art, it still has
several limitations, which we discuss next.


\noindent\textbf{Limited data-repair.} As with \ddmax, \drepair only attempts
to recover as much data as possible from a corrupt record. This means that there
is a chance of spurious interpretation of existing data (in the case of \ddmax)
and also incorporating spurious data (in the case of \drepair), either of which
may have unintended semantic consequences. While this is
worked around to some extent by means of a post processing step, with user
supplied validators, there is no guarantee that the end result is exactly same
as the non-corrupted version. That is, both \ddmax and \drepair runs the risk
of further data-corruption and information distortion, and the end-users should
select the best semantically-fit repair from the repair-candidates provided by
\drepair.

\noindent\textbf{Requirement for robust conforming parsers.}
When the parser is not conforming (i.e., does not provide \Rincomplete and \Rincorrect feedback), \drepair is unable to rely on the
guidance provided by the parser feedback. In such cases, \drepair can
still repair those parts of the format that is conforming to the feedback
requirements.

\noindent\textbf{Inability to work with context-sensitive constraints.} 
Some formats such as binary files require the format specification to be
context sensitive. That is, they require the content-length to be specified
before the content. For such formats, \drepair is of limited use.

Furthermore,  some formats may require checksums or hash values. Repairing
such extra constraints that are beyond context-free is impossible with
\drepair (and its competitors).

%\revise{
%In addition, inputs with significant semantic corruption may not be effectively repaired by \drepair. Even though \drepair is effective in fixing structural parts of invalid inputs, when the corruption is in the semantic part, the missing data becomes difficult to recover. Examples include corrupted numbers in calculations, and dates.}

\noindent\textbf{Corruptions that do not introduce immediate parse-errors.}
Certain kinds of data corruption does not introduce a parse-error immediately.
An example of this issue is the JSON string \letterboxed{[[["]]]} as we discussed
previously.
We note that, while this is a limitation, this can be worked around either
by adopting more extended repairs or by limiting \drepair repairs to deletions
if this behaviour is expected.

\noindent\textbf{Performs better when there are constraints on the data-format}
\drepair performs better when the data format is complex and has strict constraints (e.g., cJSON and TinyC).
Conversely, it performs poorly when the format is simple, and has
limited constraints (e.g., INI). This is because \drepair is able to prune
potential continuations of repair-threads early on for formats with
more constraints.

\section{Related Work}
\label{sec:relatedwork}

Let us discuss the state-of-the-art input repair approaches and how they compare to \approach. 

\subsection{Black-box Input Repair} 
A few techniques have been proposed to analyze input data without program analysis, albeit with the aim of understanding and localizing faults in the program. The earliest works were either focused on simplifying failure-inducing inputs~\cite{zeller2002simplifying, clause2009penumbra}, or isolating fault-revealing input fragments~\cite{hierarchicalDD, sterling2007automated}. Notably, the minimizing delta debugging algorithm (\ddmin) is focused on reducing failure-inducing inputs in order to diagnose and localize faults in the program. More recently, Kirschner et al.~\cite{kirschner2020debugging} proposed a maximizing variant of the delta debugging algorithm (\ddmax) to repair invalid inputs to subsets via deletion, we compare \approach to \ddmax in this work. In contrast to \ddmax, \approach also synthesizes input elements to complete input repair. 


\subsection{White and Grey-box Input Repair} Some techniques employ program analysis to fix invalid inputs. As an example, \emph{docovery}~\cite{docovery:ase14} applies symbolic execution to change broken inputs to take error-free paths in the subject program. Similarly, Ammann and Knight~\cite{data_diversity} proposed a method to transform invalid inputs into valid inputs by analyzing the region of the input causing the fault and changing those regions to avoid the fault. Unlike these methods, \approach 
is black-box, it relies on the parse-failure feedback of the subject program. 


\subsection{Constraint-based Input Repair} %via Constraint Learning:} 
These approaches automatically learn input constraints then enforce the learned constraints to repair invalid inputs~\cite{hussain2010dynamic, Demsky:2006:IED:1146238.1146266} 
These constraints are often extracted from valid inputs~\cite{Long:2012:AIR:2337223.2337233, Rinard:2007:LCZ:1297027.1297072}, specified with predicates~\cite{elkarablieh2008juzi}, model-based systems~\cite{Demsky:2003:ADR:949343.949314}, goal-directed reasoning~\cite{1553560}, dynamic symbolic execution~\cite{hussain2010dynamic} or invariants~\cite{Demsky:2006:IED:1146238.1146266}. For instance, \emph{S-DAGs}~\cite{scheffczyk2004s} enforce constraints on invalid inputs in a semi-automatic way. Unlike these approaches, \approach does not learn input constraints, it employs input synthesis and parse-failure feedback to fix invalid inputs. 


\subsection{Parser-directed Input Repair} %:}
This refers to the input repair schemes of parsers, interpreters and compilers~\cite{parr2011ll, diekmann2020dont, aho1972minimum, hammond1984survey, backhouse1979syntax}. 
These techniques employ operations such as insertion, deletion and replacement of symbols~\cite{anderson1981locally, cerecke2003locally, anderson1983assessment}, extending forward or backwards from a parser error~\cite{burke1982practical, mauney1982forward}, or more general methods of recovery and diagnosis~\cite{krawczyk1980error, aho1972minimum}. 
In this work, we compare \approach to the recovery scheme of the ANTLR parser generator~\cite{parr2011ll} which leverages the input grammar to guide input repair. %Compared to \approach, t
Unlike \approach which aims to fix an invalid input, these schemes need an input grammar, and aim to ensure the compiler does not halt while parsing. 



\section{Threats to Validity}
\label{sec:threats}

\noindent\textbf{External Validity.} This refers to the \textit{generalizability} of our approach, i.e., 
the threat that \approach may not generalize to other programs and data formats. 
To mitigate this threat, we have employed four well-known input formats with varying complexity, their corresponding programs also have  varying sizes (375 to 3062 LOC) and maturity (6 to 21 years old). 

\noindent\textbf{Internal Validity.} This concerns the \textit{correctness} of our implementation and evaluation, especially if we have correctly implemented \approach and the baselines. We mitigate this threat by testing our implementation of all approaches on small and simple test inputs to ensure the they behave as described. 

\noindent\textbf{Construct Validity.} 
%This concerns the degree to which a
%test or measurement tool actually measures the theoretical concept or construct
%it's designed to assess. In our case, 
Does the data-recovery metrics presented
represent actual data recovered? While the characters may have been recovered,
its semantic information may have been lost. This is a threat to our evaluation.
We have mitigated this threat by evaluating the amount of perfect repair accomplished.


\section{Conclusion}
\label{sec:conclusion}

This paper presents \drepair, a novel \formatfree \dtask approach that
leverages parse-failure feedback to repair corrupt data.

Through extensive evaluation on both synthetic and real-world
datasets, we demonstrated that \drepair achieves significantly higher repair
quality and data recovery rates compared to state-of-the-art techniques,
including lexical and syntactic \ddmax and ANTLR. Specifically, \drepair
delivered 31\% more perfect repairs, % VERIFIEDA
2$\times$ higher-quality repairs, % VERIFIEDB
and recovered 5.4\% more valid data on average. % VERIFIEDC

While \drepair requires slightly more time to complete repairs, with an average
runtime of about 10 seconds per repair, this is a practical trade-off given the
improvements in repair accuracy and data recovery.

We provide our implementation, experimental data and results for review:

\begin{center}
   \textbf{\url{https://anonymous.4open.science/r/drepair-C865/}} %\url{https://tinyurl.com/fsynth}}
\end{center}


\bibliographystyle{ACM-Reference-Format}
\bibliography{fse2025-drepair}

\end{document}
\endinput
%%
%% End of file `sample-acmsmall-conf.tex'.
